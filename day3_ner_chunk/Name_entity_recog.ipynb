{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker') # download the maxent chunker for name entiry recognition\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,608.0,168.0\" width=\"608px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"10.5263%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Sachin</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.26316%\" y1=\"20px\" y2=\"48px\" /><svg width=\"14.4737%\" x=\"10.5263%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Tendulkar</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.7632%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.57895%\" x=\"25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">was</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.2895%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.89474%\" x=\"31.5789%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">born</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"35.5263%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.26316%\" x=\"39.4737%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.1053%\" y1=\"20px\" y2=\"48px\" /><svg width=\"10.5263%\" x=\"44.7368%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Mumbai</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.94737%\" x=\"55.2632%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.2368%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.21053%\" x=\"59.2105%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">India</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.8158%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.26316%\" x=\"68.4211%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">on</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.0526%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.21053%\" x=\"73.6842%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">April</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.2895%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.26316%\" x=\"82.8947%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">24</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.5263%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.94737%\" x=\"88.1579%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.1316%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.89474%\" x=\"92.1053%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">1974</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.0526%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Sachin', 'NNP')]), Tree('PERSON', [('Tendulkar', 'NNP')]), ('was', 'VBD'), ('born', 'VBN'), ('in', 'IN'), Tree('GPE', [('Mumbai', 'NNP')]), (',', ','), Tree('GPE', [('India', 'NNP')]), ('on', 'IN'), ('April', 'NNP'), ('24', 'CD'), (',', ','), ('1974', 'CD')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "# sample text\n",
    "text = \"Sachin Tendulkar was born in Mumbai, India on April 24, 1974\"\n",
    "\n",
    "# tokenize the text into words\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# POS tagging\n",
    "tags = pos_tag(tokens)\n",
    "\n",
    "# performing Named Entiry Recognition(NER)\n",
    "\n",
    "ner_tree = ne_chunk(tags)\n",
    "\n",
    "# display the NER tree\n",
    "ner_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Sachin', 'NNP'), 'PERSON'),\n",
       " (('Tendulkar', 'NNP'), 'PERSON'),\n",
       " (('was', 'VBD'), 'S'),\n",
       " (('born', 'VBN'), 'S'),\n",
       " (('in', 'IN'), 'S'),\n",
       " (('Mumbai', 'NNP'), 'GPE'),\n",
       " ((',', ','), 'S'),\n",
       " (('India', 'NNP'), 'GPE'),\n",
       " (('on', 'IN'), 'S'),\n",
       " (('April', 'NNP'), 'S'),\n",
       " (('24', 'CD'), 'S'),\n",
       " ((',', ','), 'S'),\n",
       " (('1974', 'CD'), 'S')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tuple=ner_tree.pos()\n",
    "pos_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sachin', 'PERSON'),\n",
       " ('Tendulkar', 'PERSON'),\n",
       " ('Mumbai', 'GPE'),\n",
       " ('India', 'GPE')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the named entities only\n",
    "named_ent = [(ent[0], ent_tag) for ent, ent_tag in pos_tuple if ent_tag not in ['S']]\n",
    "named_ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mark Zuckerberg will meet Aditya Joshi in New York, USA on Monday 21, 2024 around 4pm to seal a $3 trillion deal."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = nlp('Mark Zuckerberg will meet Aditya Joshi in New York, USA on Monday 21, 2024 around 4pm to seal a $3 trillion deal.')\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Mark Zuckerberg,\n",
       " Aditya Joshi,\n",
       " New York,\n",
       " USA,\n",
       " Monday 21, 2024 around 4pm,\n",
       " $3 trillion)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Zuckerberg --> PERSON\n",
      "Aditya Joshi --> PERSON\n",
      "New York --> GPE\n",
      "USA --> GPE\n",
      "Monday 21, 2024 around 4pm --> DATE\n",
      "$3 trillion --> MONEY\n"
     ]
    }
   ],
   "source": [
    "# simple checking for entity of each name\n",
    "for word in sent.ents:\n",
    "    print(word.ents[0],'-->', word.label_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'People, including fictional'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to look at the explanation for an entity type\n",
    "spacy.explain('PERSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "On December 7, 2024, at 3:45 PM, a brilliant idea sparked in the bustling city of Tokyo, inspiring 3 million creators worldwide."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = nlp(\"On December 7, 2024, at 3:45 PM, a brilliant idea sparked in the bustling city of Tokyo, inspiring 3 million creators worldwide.\")\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(December 7, 2024, 3:45 PM, Tokyo, 3 million)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "December 7, 2024 --> DATE\n",
      "3:45 PM --> TIME\n",
      "Tokyo --> GPE\n",
      "3 million --> CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for word in sent1.ents:\n",
    "    print(word.ents[0],'-->', word.label_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indigenous people have lived in Alaska for thousands of years, and it is widely believed that the region served as the entry point for the initial settlement of North America by way of the Bering land bridge, which acts as a border between the Pacific Ocean and the Arctic Ocean. The Russian Empire was the first to actively colonize the area beginning in the 18th century, eventually establishing Russian America, which spanned most of the current state and promoted and maintained a native Alaskan Creole population.[7] The expense and logistical difficulty of maintaining this distant possession prompted its sale to the U.S. in 1867 for US$7.2 million (equivalent to $157 million in 2023). The area went through several administrative changes before becoming organized as a territory on May 11, 1912. It was admitted as the 49th state of the U.S. on January 3, 1959.[8]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alaska_data = \"Indigenous people have lived in Alaska for thousands of years, and it is widely believed that the region served as the entry point for the initial settlement of North America by way of the Bering land bridge, which acts as a border between the Pacific Ocean and the Arctic Ocean. The Russian Empire was the first to actively colonize the area beginning in the 18th century, eventually establishing Russian America, which spanned most of the current state and promoted and maintained a native Alaskan Creole population.[7] The expense and logistical difficulty of maintaining this distant possession prompted its sale to the U.S. in 1867 for US$7.2 million (equivalent to $157 million in 2023). The area went through several administrative changes before becoming organized as a territory on May 11, 1912. It was admitted as the 49th state of the U.S. on January 3, 1959.[8]\"\n",
    "alaska_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indigenous people have lived in Alaska for thousands of years, and it is widely believed that the region served as the entry point for the initial settlement of North America by way of the Bering land bridge, which acts as a border between the Pacific Ocean and the Arctic Ocean. The Russian Empire was the first to actively colonize the area beginning in the 18th century, eventually establishing Russian America, which spanned most of the current state and promoted and maintained a native Alaskan Creole population. The expense and logistical difficulty of maintaining this distant possession prompted its sale to the U.S. in 1867 for US$7.2 million (equivalent to $157 million in 2023). The area went through several administrative changes before becoming organized as a territory on May 11, 1912. It was admitted as the 49th state of the U.S. on January 3, 1959.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the [a-z][0-9] citation references\n",
    "import re\n",
    "regex = r'\\[[a-z0-9]+\\]'\n",
    "cleaned_data = re.sub(regex, '', alaska_data)\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indigenous people have lived in Alaska for thousands of years, and it is widely believed that the region served as the entry point for the initial settlement of North America by way of the Bering land bridge, which acts as a border between the Pacific Ocean and the Arctic Ocean. The Russian Empire was the first to actively colonize the area beginning in the 18th century, eventually establishing Russian America, which spanned most of the current state and promoted and maintained a native Alaskan Creole population. The expense and logistical difficulty of maintaining this distant possession prompted its sale to the U.S. in 1867 for US$7.2 million (equivalent to $157 million in 2023). The area went through several administrative changes before becoming organized as a territory on May 11, 1912. It was admitted as the 49th state of the U.S. on January 3, 1959."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alaska_sent = nlp(cleaned_data)\n",
    "alaska_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Alaska,\n",
       " thousands of years,\n",
       " North America,\n",
       " the Pacific Ocean,\n",
       " the Arctic Ocean,\n",
       " The Russian Empire,\n",
       " first,\n",
       " the 18th century,\n",
       " Russian America,\n",
       " Alaskan,\n",
       " U.S.,\n",
       " 1867,\n",
       " US$7.2 million,\n",
       " $157 million,\n",
       " 2023,\n",
       " May 11, 1912,\n",
       " 49th,\n",
       " U.S.,\n",
       " January 3, 1959)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alaska_sent.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alaska --> GPE\n",
      "thousands of years --> DATE\n",
      "North America --> LOC\n",
      "the Pacific Ocean --> LOC\n",
      "the Arctic Ocean --> LOC\n",
      "The Russian Empire --> GPE\n",
      "first --> ORDINAL\n",
      "the 18th century --> DATE\n",
      "Russian America --> LOC\n",
      "Alaskan --> NORP\n",
      "U.S. --> GPE\n",
      "1867 --> DATE\n",
      "US$7.2 million --> MONEY\n",
      "$157 million --> MONEY\n",
      "2023 --> DATE\n",
      "May 11, 1912 --> DATE\n",
      "49th --> ORDINAL\n",
      "U.S. --> GPE\n",
      "January 3, 1959 --> DATE\n"
     ]
    }
   ],
   "source": [
    "for word in alaska_sent.ents:\n",
    "    print(word.ents[0],'-->', word.label_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non-GPE locations, mountain ranges, bodies of water'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('LOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Indigenous people have lived in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alaska\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    thousands of years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", and it is widely believed that the region served as the entry point for the initial settlement of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    North America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " by way of the Bering land bridge, which acts as a border between \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Pacific Ocean\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Arctic Ocean\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Russian Empire\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " was the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " to actively colonize the area beginning in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the 18th century\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", eventually establishing \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Russian America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", which spanned most of the current state and promoted and maintained a native \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alaskan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " Creole population. The expense and logistical difficulty of maintaining this distant possession prompted its sale to the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1867\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US$7.2 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " (equivalent to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $157 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2023\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "). The area went through several administrative changes before becoming organized as a territory on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    May 11, 1912\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". It was admitted as the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    49th\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " state of the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    January 3, 1959\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(alaska_sent, style='ent', jupyter=True) # renders the text with the specific words and their entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('plant.n.01'),\n",
       " Synset('plant.n.02'),\n",
       " Synset('plant.n.03'),\n",
       " Synset('plant.n.04'),\n",
       " Synset('plant.v.01'),\n",
       " Synset('implant.v.01'),\n",
       " Synset('establish.v.02'),\n",
       " Synset('plant.v.04'),\n",
       " Synset('plant.v.05'),\n",
       " Synset('plant.v.06')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = wordnet.synsets('plant')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "buildings for carrying on industrial labor\n",
      "1\n",
      "(botany) a living organism lacking the power of locomotion\n",
      "2\n",
      "an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
      "3\n",
      "something planted secretly for discovery by another\n",
      "4\n",
      "put or set (seeds, seedlings, or plants) into the ground\n",
      "5\n",
      "fix or set securely or deeply\n",
      "6\n",
      "set up or lay the groundwork for\n",
      "7\n",
      "place into a river\n",
      "8\n",
      "place something or someone in a certain position in order to secretly observe or deceive\n",
      "9\n",
      "put firmly in the mind\n"
     ]
    }
   ],
   "source": [
    "# meanings of each word in the synset\n",
    "for i,word in enumerate(x):\n",
    "    print(i)\n",
    "    print(word.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = set()\n",
    "for word in wordnet.synsets('plant'):\n",
    "    synonyms.add(word.lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'establish', 'implant', 'plant'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('plant.n.01.plant'),\n",
       " Lemma('plant.n.01.works'),\n",
       " Lemma('plant.n.01.industrial_plant')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the most matching words for the given word(here its plant)\n",
    "# we are taking index as 0 since only one item is present in the list\n",
    "x[0].lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('post.n.01.post'), Lemma('post.n.01.station')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking with post\n",
    "wordnet.synsets('post')[0].lemmas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract definition and meaning from wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word and Type:  post.n.01\n",
      "Synonym:  post\n",
      "The meaning of the word:  the position where someone (as a guard or sentry) stands or is assigned to stand\n",
      "Example:  ['a soldier manned the entrance post', 'a sentry station']\n"
     ]
    }
   ],
   "source": [
    "synset = wordnet.synsets('post')\n",
    "print('Word and Type: ', synset[0].name())\n",
    "print('Synonym: ', synset[0].lemmas()[0].name())\n",
    "print('The meaning of the word: ', synset[0].definition())\n",
    "print('Example: ', str(synset[0].examples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word and Type:  post.n.11\n",
      "Synonym:  post\n",
      "The meaning of the word:  the delivery and collection of letters and packages\n",
      "Example:  ['it came by the first post', \"if you hurry you'll catch the post\"]\n"
     ]
    }
   ],
   "source": [
    "synset = wordnet.synsets('post')\n",
    "print('Word and Type: ', synset[10].name())\n",
    "print('Synonym: ', synset[10].lemmas()[0].name())\n",
    "print('The meaning of the word: ', synset[10].definition())\n",
    "print('Example: ', str(synset[10].examples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound.n.01\n",
      "sound.n.02\n",
      "sound.n.03\n",
      "sound.n.04\n",
      "audio.n.01\n",
      "phone.n.02\n",
      "strait.n.01\n",
      "sound.n.08\n"
     ]
    }
   ],
   "source": [
    "for word in wordnet.synsets('sound', pos='n'):\n",
    "    print(word.name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read a word from user and print all meanings of it\n",
    "# read a word from user and print all noun meanings of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = input(\"Enter a word here: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. flower.n.01 --> a plant cultivated for its blooms or blossoms\n",
      "1. flower.n.02 --> reproductive organ of angiosperm plants especially one having showy or colorful parts\n",
      "2. flower.n.03 --> the period of greatest prosperity or productivity\n"
     ]
    }
   ],
   "source": [
    "synsets_word = wordnet.synsets(word, pos='n') # extracting all meanings of noun type synonyms\n",
    "\n",
    "for i,word in enumerate(synsets_word):\n",
    "    print(f\"{i}. {word.name()} --> {word.definition()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different forms of the meaning for a word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = set()\n",
    "nouns = set()\n",
    "adj = set()\n",
    " \n",
    "for word in wordnet.synsets('head', pos='n'):\n",
    "    nouns.add(word.lemmas()[0].name())\n",
    "for word in wordnet.synsets('head', pos='v'):\n",
    "    verbs.add(word.lemmas()[0].name())\n",
    "for word in wordnet.synsets('head', pos='a'):\n",
    "    adj.add(word.lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head', 'lead', 'steer'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs #.remove('sound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capitulum',\n",
       " 'drumhead',\n",
       " 'forefront',\n",
       " 'fountainhead',\n",
       " 'head',\n",
       " 'heading',\n",
       " 'headway',\n",
       " 'mind',\n",
       " 'oral_sex',\n",
       " 'pass',\n",
       " 'point',\n",
       " 'principal',\n",
       " 'promontory',\n",
       " 'question',\n",
       " 'read/write_head'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antonyms:  {'maximum', 'maximal'}\n"
     ]
    }
   ],
   "source": [
    "ant = set()\n",
    "for synset in wordnet.synsets(\"minimal\"):\n",
    "    for lemma in synset.lemmas():\n",
    "        if lemma.antonyms(): # when the lemma has some \n",
    "            ant.add(lemma.antonyms()[0].name())\n",
    "print('Antonyms: ',ant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gas.n.02 is a hypernym of air \n",
      "region.n.01 is a hypernym of air \n",
      "quality.n.01 is a hypernym of air \n",
      "wind.n.01 is a hypernym of air \n",
      "region.n.01 is a hypernym of air \n",
      "element.n.05 is a hypernym of air \n",
      "music.n.01 is a hypernym of air \n",
      "medium.n.03 is a hypernym of air \n",
      "travel.n.01 is a hypernym of air \n",
      "expose.v.01 is a hypernym of air \n",
      "publicize.v.01 is a hypernym of air \n",
      "tell.v.02 is a hypernym of air \n",
      "dry.v.01 is a hypernym of air \n",
      "refresh.v.02 is a hypernym of air \n"
     ]
    }
   ],
   "source": [
    "word = 'air'\n",
    "synsets = wordnet.synsets(word)\n",
    "for synset in synsets:\n",
    "    # Get hypernyms(parent concepts)\n",
    "    hypernyms = synset.hypernyms()\n",
    "    # check if there are any hypernyms and then print them\n",
    "    if hypernyms:\n",
    "        # print here\n",
    "        for hypernym in hypernyms:\n",
    "            print(f\"{hypernym.name()} is a hypernym of {word} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole_blood.n.01 is a hyponym of blood\n",
      "venous_blood.n.01 is a hyponym of blood\n",
      "cord_blood.n.01 is a hyponym of blood\n",
      "bloodstream.n.01 is a hyponym of blood\n",
      "blood_group.n.01 is a hyponym of blood\n",
      "lifeblood.n.01 is a hyponym of blood\n",
      "blood_clot.n.01 is a hyponym of blood\n",
      "gore.n.02 is a hyponym of blood\n",
      "menorrhea.n.01 is a hyponym of blood\n",
      "arterial_blood.n.01 is a hyponym of blood\n",
      "side.n.08 is a hyponym of blood\n",
      "family.n.04 is a hyponym of blood\n"
     ]
    }
   ],
   "source": [
    "word = 'blood'\n",
    "synsets = wordnet.synsets(word)\n",
    "for synset in synsets:\n",
    "    # Get hyponyms(child concepts)\n",
    "    hyponyms = synset.hyponyms()\n",
    "    # check if there are any hyponyms and then print them\n",
    "    if hyponyms:\n",
    "        # print here\n",
    "        for hyponym in hyponyms:\n",
    "            print(f\"{hyponym.name()} is a hyponym of {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cathode-ray_tube.n.01 is a meronym of computer\n",
      "peripheral.n.01 is a meronym of computer\n",
      "keyboard.n.01 is a meronym of computer\n",
      "monitor.n.04 is a meronym of computer\n",
      "data_converter.n.01 is a meronym of computer\n",
      "central_processing_unit.n.01 is a meronym of computer\n",
      "chip.n.07 is a meronym of computer\n",
      "busbar.n.01 is a meronym of computer\n",
      "computer_circuit.n.01 is a meronym of computer\n",
      "diskette.n.01 is a meronym of computer\n",
      "memory.n.04 is a meronym of computer\n",
      "computer_accessory.n.01 is a meronym of computer\n",
      "hardware.n.03 is a meronym of computer\n",
      "disk_cache.n.01 is a meronym of computer\n"
     ]
    }
   ],
   "source": [
    "word = 'computer'\n",
    "\n",
    "synsets = wordnet.synsets(word)\n",
    "\n",
    "for synset in synsets:\n",
    "    # get meronyms(part concepts)\n",
    "    meronyms = synset.part_meronyms()\n",
    "    # check if there are any meronyms and then print them\n",
    "    if meronyms:\n",
    "        for meronym in meronyms:\n",
    "            print(f\"{meronym.name()} is a meronym of {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find holonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'planet'\n",
    "\n",
    "synsets = wordnet.synsets(word)\n",
    "\n",
    "for synset in synsets:\n",
    "    # get holonyms(whole concepts)\n",
    "    holonyms = synset.part_holonyms()\n",
    "    # check if there are any holonyms and then print them\n",
    "    if holonyms:\n",
    "        for holonym in holonyms:\n",
    "            print(f\"{holonym.name()} is a holonym of {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLNov2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
