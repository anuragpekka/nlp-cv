{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize # word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') #tokenization\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords') #collection of stopwords\n",
    "nltk.download('wordnet') #WORDNET -> DATABASE OF ENGLISH WORDS\n",
    "nltk.download('omw-1.4') #open multilinguial wordnet\n",
    "nltk.download('averaged_perceptron_tagger') # POS tagging\n",
    "nltk.download('indian') # INDIAN language POS tagging\n",
    "nltk.download('maxent_ne_chunker') # NER tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'à¤…à¤ªà¥à¤°à¤¸à¤¾à¤° à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ (à¤¦ à¤¨à¥‰à¤¨ à¤ªà¥à¤°à¥‹à¤²à¤¿à¤«à¤°à¥‡à¤¶à¤¨ à¤°à¤¿à¤µà¥à¤¯à¥‚) à¤®à¥‡à¤‚ à¤›à¤ªà¥‡ à¤à¤• à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨ à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤°, à¥§à¥¯à¥¯à¥« à¤•à¥€ à¤¸à¤°à¥à¤¦à¤¿à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚, à¤¸à¥‚à¤°à¥à¤¯à¤¾ à¤­à¤¾à¤°à¤¤ à¤•à¤¾ à¤µà¤¿à¤•à¤¸à¤¿à¤¤ à¤•à¤¿à¤¯à¤¾ à¤œà¤¾ à¤°à¤¹à¤¾ à¤ªà¥à¤°à¤¥à¤® à¤…à¤‚à¤¤à¤°à¤®à¤¹à¤¾à¤¦à¥à¤µà¥€à¤ªà¥€à¤¯ à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤£ à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤¾à¤¸à¥à¤¤à¥à¤° à¤•à¤¾ à¤•à¥‚à¤Ÿà¤¨à¤¾à¤® à¤¹à¥ˆ. à¤®à¤¾à¤¨à¤¾ à¤œà¤¾à¤¤à¤¾ à¤¹à¥ˆ à¤•à¥€ à¤°à¤•à¥à¤·à¤¾ à¤…à¤¨à¥à¤¸à¤‚à¤§à¤¾à¤¨ à¤à¤µà¤‚ à¤µà¤¿à¤•à¤¾à¤¸ à¤¸à¤‚à¤—à¤ à¤¨ (à¤¡à¥€.à¤†à¤°.à¤¡à¥€.à¤“) à¤¨à¥‡ à¥§à¥¯à¥¯à¥ª à¤®à¥‡à¤‚ à¤‡à¤¸ à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾ à¤•à¥‹ à¤†à¤°à¤‚à¤­ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆ. à¤‡à¤¸ à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨ à¤•à¥€ à¥¨à¥¦à¥¦à¥¯ à¤¤à¤• à¤•à¤¿à¤¸à¥€ à¤…à¤¨à¥à¤¯ à¤¸à¥à¤°à¥‹à¤¤ à¤¸à¥‡ à¤ªà¥à¤·à¥à¤Ÿà¤¿ à¤¨à¤¹à¥€à¤‚ à¤•à¥€ à¤—à¤ˆ à¤¹à¥ˆ. à¤­à¤¾à¤°à¤¤ à¤¸à¤°à¤•à¤¾à¤° à¤•à¥‡ à¤…à¤§à¤¿à¤•à¤¾à¤°à¤¿à¤¯à¥‹à¤‚ à¤¨à¥‡ à¤¬à¤¾à¤°-à¤¬à¤¾à¤° à¤‡à¤¸ à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾ à¤•à¥‡ à¤…à¤¸à¥à¤¤à¤¿à¤¤à¥à¤µ à¤•à¤¾ à¤–à¤£à¥à¤¡à¤¨ à¤•à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨ à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤°, à¤¸à¥‚à¤°à¥à¤¯à¤¾ à¤à¤• à¤…à¤‚à¤¤à¤°à¤®à¤¹à¤¾à¤¦à¥à¤µà¥€à¤ªà¥€à¤¯-à¤¦à¥‚à¤°à¥€ à¤•à¤¾, à¤¸à¤¤à¤¹ à¤ªà¤° à¤†à¤§à¤¾à¤°à¤¿à¤¤, à¤ à¥‹à¤¸ à¤”à¤° à¤¤à¤°à¤² à¤ªà¥à¤°à¤£à¥‹à¤¦à¤• (à¤ªà¥à¤°à¥‹à¤ªà¥‡à¤²à¥‡à¤‚à¤Ÿ) à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤¾à¤¸à¥à¤¤à¥à¤° à¤¹à¥ˆ. à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨ à¤®à¥‡à¤‚ à¤†à¤—à¥‡ à¤•à¤¹à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆ à¤•à¤¿ à¤¸à¥‚à¤°à¥à¤¯à¤¾ à¤­à¤¾à¤°à¤¤ à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤®à¤¹à¤¤à¥à¤µà¤¾à¤•à¤¾à¤‚à¤•à¥à¤·à¥€ à¤à¤•à¥€à¤•à¥ƒà¤¤ à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤¿à¤¤ à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤¾à¤¸à¥à¤¤à¥à¤° à¤µà¤¿à¤•à¤¾à¤¸ à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾ à¤¹à¥ˆ. à¤¸à¥‚à¤°à¥à¤¯à¤¾ à¤•à¥€ à¤®à¤¾à¤°à¤• à¤•à¥à¤·à¤®à¤¤à¤¾ à¥®,à¥¦à¥¦à¥¦ à¤¸à¥‡ à¥§à¥¨,à¥¦à¥¦à¥¦ à¤•à¤¿à¤²à¥‹à¤®à¥€à¤Ÿà¤° à¤¤à¤• à¤…à¤¨à¥à¤®à¤¾à¤¨à¤¿à¤¤ à¤¹à¥ˆ.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['à¤…à¤ªà¥à¤°à¤¸à¤¾à¤°',\n",
       " 'à¤¸à¤®à¥€à¤•à¥à¤·à¤¾',\n",
       " '(',\n",
       " 'à¤¦',\n",
       " 'à¤¨à¥‰à¤¨',\n",
       " 'à¤ªà¥à¤°à¥‹à¤²à¤¿à¤«à¤°à¥‡à¤¶à¤¨',\n",
       " 'à¤°à¤¿à¤µà¥à¤¯à¥‚',\n",
       " ')',\n",
       " 'à¤®à¥‡à¤‚',\n",
       " 'à¤›à¤ªà¥‡',\n",
       " 'à¤à¤•',\n",
       " 'à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨',\n",
       " 'à¤•à¥‡',\n",
       " 'à¤…à¤¨à¥à¤¸à¤¾à¤°',\n",
       " ',',\n",
       " 'à¥§à¥¯à¥¯à¥«',\n",
       " 'à¤•à¥€',\n",
       " 'à¤¸à¤°à¥à¤¦à¤¿à¤¯à¥‹à¤‚',\n",
       " 'à¤®à¥‡à¤‚',\n",
       " ',',\n",
       " 'à¤¸à¥‚à¤°à¥à¤¯à¤¾',\n",
       " 'à¤­à¤¾à¤°à¤¤',\n",
       " 'à¤•à¤¾',\n",
       " 'à¤µà¤¿à¤•à¤¸à¤¿à¤¤',\n",
       " 'à¤•à¤¿à¤¯à¤¾',\n",
       " 'à¤œà¤¾',\n",
       " 'à¤°à¤¹à¤¾',\n",
       " 'à¤ªà¥à¤°à¤¥à¤®',\n",
       " 'à¤…à¤‚à¤¤à¤°à¤®à¤¹à¤¾à¤¦à¥à¤µà¥€à¤ªà¥€à¤¯',\n",
       " 'à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤£',\n",
       " 'à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤¾à¤¸à¥à¤¤à¥à¤°',\n",
       " 'à¤•à¤¾',\n",
       " 'à¤•à¥‚à¤Ÿà¤¨à¤¾à¤®',\n",
       " 'à¤¹à¥ˆ',\n",
       " '.',\n",
       " 'à¤®à¤¾à¤¨à¤¾',\n",
       " 'à¤œà¤¾à¤¤à¤¾',\n",
       " 'à¤¹à¥ˆ',\n",
       " 'à¤•à¥€',\n",
       " 'à¤°à¤•à¥à¤·à¤¾',\n",
       " 'à¤…à¤¨à¥à¤¸à¤‚à¤§à¤¾à¤¨',\n",
       " 'à¤à¤µà¤‚',\n",
       " 'à¤µà¤¿à¤•à¤¾à¤¸',\n",
       " 'à¤¸à¤‚à¤—à¤ à¤¨',\n",
       " '(',\n",
       " 'à¤¡à¥€.à¤†à¤°.à¤¡à¥€.à¤“',\n",
       " ')',\n",
       " 'à¤¨à¥‡',\n",
       " 'à¥§à¥¯à¥¯à¥ª',\n",
       " 'à¤®à¥‡à¤‚',\n",
       " 'à¤‡à¤¸',\n",
       " 'à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾',\n",
       " 'à¤•à¥‹',\n",
       " 'à¤†à¤°à¤‚à¤­',\n",
       " 'à¤•à¤°',\n",
       " 'à¤¦à¤¿à¤¯à¤¾',\n",
       " 'à¤¹à¥ˆ',\n",
       " '.',\n",
       " 'à¤‡à¤¸',\n",
       " 'à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨',\n",
       " 'à¤•à¥€',\n",
       " 'à¥¨à¥¦à¥¦à¥¯',\n",
       " 'à¤¤à¤•',\n",
       " 'à¤•à¤¿à¤¸à¥€',\n",
       " 'à¤…à¤¨à¥à¤¯',\n",
       " 'à¤¸à¥à¤°à¥‹à¤¤',\n",
       " 'à¤¸à¥‡',\n",
       " 'à¤ªà¥à¤·à¥à¤Ÿà¤¿',\n",
       " 'à¤¨à¤¹à¥€à¤‚',\n",
       " 'à¤•à¥€',\n",
       " 'à¤—à¤ˆ',\n",
       " 'à¤¹à¥ˆ',\n",
       " '.',\n",
       " 'à¤­à¤¾à¤°à¤¤',\n",
       " 'à¤¸à¤°à¤•à¤¾à¤°',\n",
       " 'à¤•à¥‡',\n",
       " 'à¤…à¤§à¤¿à¤•à¤¾à¤°à¤¿à¤¯à¥‹à¤‚',\n",
       " 'à¤¨à¥‡',\n",
       " 'à¤¬à¤¾à¤°-à¤¬à¤¾à¤°',\n",
       " 'à¤‡à¤¸',\n",
       " 'à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾',\n",
       " 'à¤•à¥‡',\n",
       " 'à¤…à¤¸à¥à¤¤à¤¿à¤¤à¥à¤µ',\n",
       " 'à¤•à¤¾',\n",
       " 'à¤–à¤£à¥à¤¡à¤¨',\n",
       " 'à¤•à¤¿à¤¯à¤¾',\n",
       " 'à¤¹à¥ˆà¥¤à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨',\n",
       " 'à¤•à¥‡',\n",
       " 'à¤…à¤¨à¥à¤¸à¤¾à¤°',\n",
       " ',',\n",
       " 'à¤¸à¥‚à¤°à¥à¤¯à¤¾',\n",
       " 'à¤à¤•',\n",
       " 'à¤…à¤‚à¤¤à¤°à¤®à¤¹à¤¾à¤¦à¥à¤µà¥€à¤ªà¥€à¤¯-à¤¦à¥‚à¤°à¥€',\n",
       " 'à¤•à¤¾',\n",
       " ',',\n",
       " 'à¤¸à¤¤à¤¹',\n",
       " 'à¤ªà¤°',\n",
       " 'à¤†à¤§à¤¾à¤°à¤¿à¤¤',\n",
       " ',',\n",
       " 'à¤ à¥‹à¤¸',\n",
       " 'à¤”à¤°',\n",
       " 'à¤¤à¤°à¤²',\n",
       " 'à¤ªà¥à¤°à¤£à¥‹à¤¦à¤•',\n",
       " '(',\n",
       " 'à¤ªà¥à¤°à¥‹à¤ªà¥‡à¤²à¥‡à¤‚à¤Ÿ',\n",
       " ')',\n",
       " 'à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤¾à¤¸à¥à¤¤à¥à¤°',\n",
       " 'à¤¹à¥ˆ',\n",
       " '.',\n",
       " 'à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨',\n",
       " 'à¤®à¥‡à¤‚',\n",
       " 'à¤†à¤—à¥‡',\n",
       " 'à¤•à¤¹à¤¾',\n",
       " 'à¤—à¤¯à¤¾',\n",
       " 'à¤¹à¥ˆ',\n",
       " 'à¤•à¤¿',\n",
       " 'à¤¸à¥‚à¤°à¥à¤¯à¤¾',\n",
       " 'à¤­à¤¾à¤°à¤¤',\n",
       " 'à¤•à¥€',\n",
       " 'à¤¸à¤¬à¤¸à¥‡',\n",
       " 'à¤®à¤¹à¤¤à¥à¤µà¤¾à¤•à¤¾à¤‚à¤•à¥à¤·à¥€',\n",
       " 'à¤à¤•à¥€à¤•à¥ƒà¤¤',\n",
       " 'à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤¿à¤¤',\n",
       " 'à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤¾à¤¸à¥à¤¤à¥à¤°',\n",
       " 'à¤µà¤¿à¤•à¤¾à¤¸',\n",
       " 'à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾',\n",
       " 'à¤¹à¥ˆ',\n",
       " '.',\n",
       " 'à¤¸à¥‚à¤°à¥à¤¯à¤¾',\n",
       " 'à¤•à¥€',\n",
       " 'à¤®à¤¾à¤°à¤•',\n",
       " 'à¤•à¥à¤·à¤®à¤¤à¤¾',\n",
       " 'à¥®,à¥¦à¥¦à¥¦',\n",
       " 'à¤¸à¥‡',\n",
       " 'à¥§à¥¨,à¥¦à¥¦à¥¦',\n",
       " 'à¤•à¤¿à¤²à¥‹à¤®à¥€à¤Ÿà¤°',\n",
       " 'à¤¤à¤•',\n",
       " 'à¤…à¤¨à¥à¤®à¤¾à¤¨à¤¿à¤¤',\n",
       " 'à¤¹à¥ˆ',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing sentences\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Hello friends!\n",
    "How are you?    Welcome to the world of \n",
    "Python Programming.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!',\n",
       " 'How are you?',\n",
       " 'Welcome to the world of Python Programming.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['à¤…à¤ªà¥à¤°à¤¸à¤¾à¤° à¤¸à¤®à¥€à¤•à¥à¤·à¤¾ (à¤¦ à¤¨à¥‰à¤¨ à¤ªà¥à¤°à¥‹à¤²à¤¿à¤«à¤°à¥‡à¤¶à¤¨ à¤°à¤¿à¤µà¥à¤¯à¥‚) à¤®à¥‡à¤‚ à¤›à¤ªà¥‡ à¤à¤• à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨ à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤°, à¥§à¥¯à¥¯à¥« à¤•à¥€ à¤¸à¤°à¥à¤¦à¤¿à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚, à¤¸à¥‚à¤°à¥à¤¯à¤¾ à¤­à¤¾à¤°à¤¤ à¤•à¤¾ à¤µà¤¿à¤•à¤¸à¤¿à¤¤ à¤•à¤¿à¤¯à¤¾ à¤œà¤¾ à¤°à¤¹à¤¾ à¤ªà¥à¤°à¤¥à¤® à¤…à¤‚à¤¤à¤°à¤®à¤¹à¤¾à¤¦à¥à¤µà¥€à¤ªà¥€à¤¯ à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤£ à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤¾à¤¸à¥à¤¤à¥à¤° à¤•à¤¾ à¤•à¥‚à¤Ÿà¤¨à¤¾à¤® à¤¹à¥ˆ.',\n",
       " 'à¤®à¤¾à¤¨à¤¾ à¤œà¤¾à¤¤à¤¾ à¤¹à¥ˆ à¤•à¥€ à¤°à¤•à¥à¤·à¤¾ à¤…à¤¨à¥à¤¸à¤‚à¤§à¤¾à¤¨ à¤à¤µà¤‚ à¤µà¤¿à¤•à¤¾à¤¸ à¤¸à¤‚à¤—à¤ à¤¨ (à¤¡à¥€.à¤†à¤°.à¤¡à¥€.à¤“) à¤¨à¥‡ à¥§à¥¯à¥¯à¥ª à¤®à¥‡à¤‚ à¤‡à¤¸ à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾ à¤•à¥‹ à¤†à¤°à¤‚à¤­ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆ.',\n",
       " 'à¤‡à¤¸ à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨ à¤•à¥€ à¥¨à¥¦à¥¦à¥¯ à¤¤à¤• à¤•à¤¿à¤¸à¥€ à¤…à¤¨à¥à¤¯ à¤¸à¥à¤°à¥‹à¤¤ à¤¸à¥‡ à¤ªà¥à¤·à¥à¤Ÿà¤¿ à¤¨à¤¹à¥€à¤‚ à¤•à¥€ à¤—à¤ˆ à¤¹à¥ˆ.',\n",
       " 'à¤­à¤¾à¤°à¤¤ à¤¸à¤°à¤•à¤¾à¤° à¤•à¥‡ à¤…à¤§à¤¿à¤•à¤¾à¤°à¤¿à¤¯à¥‹à¤‚ à¤¨à¥‡ à¤¬à¤¾à¤°-à¤¬à¤¾à¤° à¤‡à¤¸ à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾ à¤•à¥‡ à¤…à¤¸à¥à¤¤à¤¿à¤¤à¥à¤µ à¤•à¤¾ à¤–à¤£à¥à¤¡à¤¨ à¤•à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨ à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤°, à¤¸à¥‚à¤°à¥à¤¯à¤¾ à¤à¤• à¤…à¤‚à¤¤à¤°à¤®à¤¹à¤¾à¤¦à¥à¤µà¥€à¤ªà¥€à¤¯-à¤¦à¥‚à¤°à¥€ à¤•à¤¾, à¤¸à¤¤à¤¹ à¤ªà¤° à¤†à¤§à¤¾à¤°à¤¿à¤¤, à¤ à¥‹à¤¸ à¤”à¤° à¤¤à¤°à¤² à¤ªà¥à¤°à¤£à¥‹à¤¦à¤• (à¤ªà¥à¤°à¥‹à¤ªà¥‡à¤²à¥‡à¤‚à¤Ÿ) à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤¾à¤¸à¥à¤¤à¥à¤° à¤¹à¥ˆ.',\n",
       " 'à¤ªà¥à¤°à¤¤à¤¿à¤µà¥‡à¤¦à¤¨ à¤®à¥‡à¤‚ à¤†à¤—à¥‡ à¤•à¤¹à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆ à¤•à¤¿ à¤¸à¥‚à¤°à¥à¤¯à¤¾ à¤­à¤¾à¤°à¤¤ à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤®à¤¹à¤¤à¥à¤µà¤¾à¤•à¤¾à¤‚à¤•à¥à¤·à¥€ à¤à¤•à¥€à¤•à¥ƒà¤¤ à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤¿à¤¤ à¤ªà¥à¤°à¤•à¥à¤·à¥‡à¤ªà¤¾à¤¸à¥à¤¤à¥à¤° à¤µà¤¿à¤•à¤¾à¤¸ à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾ à¤¹à¥ˆ.',\n",
       " 'à¤¸à¥‚à¤°à¥à¤¯à¤¾ à¤•à¥€ à¤®à¤¾à¤°à¤• à¤•à¥à¤·à¤®à¤¤à¤¾ à¥®,à¥¦à¥¦à¥¦ à¤¸à¥‡ à¥§à¥¨,à¥¦à¥¦à¥¦ à¤•à¤¿à¤²à¥‹à¤®à¥€à¤Ÿà¤° à¤¤à¤• à¤…à¤¨à¥à¤®à¤¾à¤¨à¤¿à¤¤ à¤¹à¥ˆ.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sent) # the full stop symbol should match english full stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "india_wiki = '''India, officially the Republic of India,[j][20] is a country in South Asia. It is the seventh-largest country in the world by area and the most populous country. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[k] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia.\n",
    "\n",
    "Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[22][23][24] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26] By at least 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest.[27][28] Its evidence today is found in the hymns of the Rigveda. Preserved by an oral tradition that was resolutely vigilant, the Rigveda records the dawning of Hinduism in India.[29] The Dravidian languages of India were supplanted in the northern and western regions.[30] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[31] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[32] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.[33] Their collective era was suffused with wide-ranging creativity,[34] but also marked by the declining status of women,[35] and the incorporation of untouchability into an organised system of belief.[l][36] The Middle kingdoms exported Sanskrit language, south Indian scripts and religions of Hinduism and Buddhism to the Southeast Asia.[37]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'India, officially the Republic of India,[j][20] is a country in South Asia. It is the seventh-largest country in the world by area and the most populous country. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[k] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia.\\n\\nModern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[22][23][24] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26] By at least 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest.[27][28] Its evidence today is found in the hymns of the Rigveda. Preserved by an oral tradition that was resolutely vigilant, the Rigveda records the dawning of Hinduism in India.[29] The Dravidian languages of India were supplanted in the northern and western regions.[30] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[31] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[32] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.[33] Their collective era was suffused with wide-ranging creativity,[34] but also marked by the declining status of women,[35] and the incorporation of untouchability into an organised system of belief.[l][36] The Middle kingdoms exported Sanskrit language, south Indian scripts and religions of Hinduism and Buddhism to the Southeast Asia.[37]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India, officially the Republic of India,[j][20] is a country in South Asia.',\n",
       " 'It is the seventh-largest country in the world by area and the most populous country.',\n",
       " 'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[k] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.',\n",
       " 'In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia.',\n",
       " 'Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.',\n",
       " '[22][23][24] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.',\n",
       " '[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.',\n",
       " '[26] By at least 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest.',\n",
       " '[27][28] Its evidence today is found in the hymns of the Rigveda.',\n",
       " 'Preserved by an oral tradition that was resolutely vigilant, the Rigveda records the dawning of Hinduism in India.',\n",
       " '[29] The Dravidian languages of India were supplanted in the northern and western regions.',\n",
       " '[30] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[31] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.',\n",
       " '[32] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.',\n",
       " '[33] Their collective era was suffused with wide-ranging creativity,[34] but also marked by the declining status of women,[35] and the incorporation of untouchability into an organised system of belief.',\n",
       " '[l][36] The Middle kingdoms exported Sanskrit language, south Indian scripts and religions of Hinduism and Buddhism to the Southeast Asia.',\n",
       " '[37]']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing a sentence that has the maximum number of 'the'\n",
    "indi_sent = sent_tokenize(india_wiki) # sentence tokenize here\n",
    "indi_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of 'the': 9\n",
      "Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[k] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.\n"
     ]
    }
   ],
   "source": [
    "# sent tokenize and word tokenize inside it\n",
    "max = 0\n",
    "for sents in indi_sent:\n",
    "    words = word_tokenize(sents.lower()) # word tokenize here\n",
    "    count_the = words.count('the')\n",
    "    if(count_the > max):\n",
    "        max = count_the\n",
    "        max_sent = sents\n",
    "        \n",
    "print(f\"The count of 'the': {max}\")\n",
    "print(max_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whitespace tokenizer(splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'friends!', 'How', 'are', 'you?', 'Welcome', 'to', 'the', 'world', 'of', 'Python', 'Programming.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "# a whitespace consists of a newline, tab and spaces\n",
    "tk = WhitespaceTokenizer()\n",
    "wht = tk.tokenize(text)\n",
    "print(wht)\n",
    "len(wht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'friends!\\nHow', 'are', 'you?', '', '', '', 'Welcome', 'to', 'the', 'world', 'of', '\\nPython', 'Programming.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# space tokenizer\n",
    "# newlines and tabs are not recognized here\n",
    "from nltk.tokenize import SpaceTokenizer\n",
    "st = SpaceTokenizer() \n",
    "spt = st.tokenize(text)\n",
    "print(spt)\n",
    "len(spt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello friends!', 'How are you?    Welcome to the world of ', 'Python Programming.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Line tokenizer\n",
    "from nltk.tokenize import LineTokenizer\n",
    "lt = LineTokenizer()\n",
    "ltw = lt.tokenize(text) \n",
    "print(ltw)\n",
    "len(ltw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello friends!\\nHow are you?', 'Welcome to the world of \\nPython', 'Programming.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tab tokenizer\n",
    "from nltk.tokenize import TabTokenizer\n",
    "tb = TabTokenizer()\n",
    "text1 = '''Hello friends!\n",
    "How are you?\\tWelcome to the world of \n",
    "Python\\tProgramming.'''\n",
    "text_tb = tb.tokenize(text1)\n",
    "print(text_tb)\n",
    "len(text_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oil', 'up', 'buddy', ':)', \"I'll\", 'touch', 'you', 'tonight', ':D', \"I'll\", 'be', 'gooning', 'to', 'you', 'forever', '<3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweet tokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "twt = TweetTokenizer()\n",
    "data = \"Oil up buddy:) I'll touch you tonight:D I'll be gooning to you forever<3\"\n",
    "twt_data = twt.tokenize(data)\n",
    "print(twt_data)\n",
    "len(twt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oil', 'up', 'buddy', ':)', 'ðŸ˜Ž', \"I'll\", 'touch', 'you', 'tonight', ':D', 'ðŸ˜Š', '.', \"I'll\", 'be', 'gooning', 'ðŸ§œ', 'ðŸŽ¶', 'ðŸš', 'to', 'you', 'forever', '<3', '!', '!', '!', 'ðŸ—¿']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweet tokenizer with emojis\n",
    "data_emo = \"Oil up buddy:)ðŸ˜Ž I'll touch you tonight:DðŸ˜Š. I'll be gooningðŸ§œðŸŽ¶ðŸš to you forever<3!!!!ðŸ—¿\"\n",
    "twt_emo = twt.tokenize(data_emo)\n",
    "print(twt_emo)\n",
    "len(twt_emo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Van-Rossum', 'is', 'in', 'Pune', 'today', '.', 'We', 'welcomed', 'Van-Rossum', 'here', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MWE tokenizer(multiword)\n",
    "mwe_text = \"Van Rossum is in Pune today. We welcomed Van Rossum here.\"\n",
    "from nltk.tokenize import MWETokenizer\n",
    "mwe = MWETokenizer(separator='-') # changing the separator from the default '_'\n",
    "mwe.add_mwe(('Van','Rossum')) # adding this tuple of words to group together\n",
    "mwe_final = mwe.tokenize(word_tokenize(mwe_text)) # words are first tokenized and then the given tuple of words are grouped together, separated by the separator\n",
    "print(mwe_final)\n",
    "len(mwe_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: \n",
      "['This', 'is', 'some', 'text', 'with', 'punctuation', '>', \"Let's\", 'tokenize', 'this', 'shi', 'OK', 'blud', '']\n"
     ]
    }
   ],
   "source": [
    "# custom tokenizer\n",
    "import re\n",
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"[.,;?\\s]+\",text)\n",
    "\n",
    "text = \"This is some text with punctuation > Let's tokenize this shi. OK blud?\"\n",
    "tokens = custom_tokenizer(text)\n",
    "print('Tokens: ')\n",
    "# for token in tokens:\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLNov2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
